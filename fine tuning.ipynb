{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Complete Fine-Tuning Guide: Teaching AI Your Language\n",
    "## From Pre-trained Models to Custom Solutions - A Step-by-Step Journey\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘‹ Welcome to Fine-Tuning!\n",
    "\n",
    "Today we're going to take a journey from a general AI model to YOUR specialized AI assistant.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ What Will We Achieve Today?\n",
    "\n",
    "By the end of this session, you will:\n",
    "1. **Understand** what fine-tuning really means (with lots of examples!)\n",
    "2. **Learn** every step of the fine-tuning process\n",
    "3. **Build** your own sentiment analyzer for movie reviews\n",
    "4. **Deploy** your model so anyone can use it\n",
    "5. **Test** with real examples and see it work!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤” Part 1: What is Fine-Tuning? Let's Really Understand It!\n",
    "\n",
    "### ğŸ“ The University Analogy\n",
    "\n",
    "Imagine you have a university graduate (that's our pre-trained model):\n",
    "- âœ… They know general stuff: math, science, language\n",
    "- âŒ But they don't know YOUR specific job\n",
    "\n",
    "Fine-tuning is like:\n",
    "- ğŸ“š Giving them specialized training for YOUR company\n",
    "- ğŸ¯ Teaching them YOUR specific terminology\n",
    "- ğŸ’¼ Making them an expert in YOUR field\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”Œ For Electrical Engineers: The Specialist Analogy\n",
    "\n",
    "Think of it this way:\n",
    "\n",
    "```\n",
    "General Electrician (Pre-trained Model):\n",
    "  - Knows: Basic wiring, safety, circuits\n",
    "  - Can do: General electrical work\n",
    "  \n",
    "        â¬‡ï¸ FINE-TUNING â¬‡ï¸\n",
    "        \n",
    "Power Grid Specialist (Your Fine-tuned Model):\n",
    "  - Knows: Transformer stations, grid management, load balancing\n",
    "  - Expert in: YOUR specific area\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Real Examples: Before vs After Fine-Tuning\n",
    "\n",
    "Let's see what happens when we fine-tune:\n",
    "\n",
    "### Example 1: General vs Specialized\n",
    "\n",
    "| Input Text | General Model Says | Fine-tuned Model Says | Why? |\n",
    "|------------|-------------------|----------------------|------|\n",
    "| \"The transformer failed\" | \"Something changed form\" ğŸ¤· | \"Equipment malfunction\" âš¡ | Knows electrical context |\n",
    "| \"High resistance in circuit\" | \"Someone is resisting\" ğŸ¤· | \"Electrical issue detected\" âš¡ | Understands terminology |\n",
    "| \"The plot was shocking\" | \"Electricity involved?\" ğŸ¤· | \"Surprising story\" ğŸ¬ | Trained on movie reviews |\n",
    "\n",
    "### Example 2: Confidence Levels\n",
    "\n",
    "For the text: \"This movie is absolutely terrible\"\n",
    "\n",
    "- **General Model**: \n",
    "  - Negative: 65% confidence\n",
    "  - \"I think it's negative but not sure\"\n",
    "  \n",
    "- **Fine-tuned Model**:\n",
    "  - Negative: 98% confidence\n",
    "  - \"Definitely negative, I've seen thousands of movie reviews!\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ The Complete Fine-Tuning Process - Visual Guide\n",
    "\n",
    "Here's what we'll do today, step by step:\n",
    "\n",
    "```\n",
    "STEP 1: GET A SMART MODEL\n",
    "    ğŸ“¦ Download pre-trained model (already knows language)\n",
    "         |\n",
    "         v\n",
    "STEP 2: PREPARE YOUR DATA\n",
    "    ğŸ“ Get your movie reviews ready\n",
    "    ğŸ·ï¸ Label them (positive/negative)\n",
    "         |\n",
    "         v\n",
    "STEP 3: TEACH THE MODEL\n",
    "    ğŸ“ Show examples: \"This text = Positive\"\n",
    "    ğŸ” Repeat many times (epochs)\n",
    "    ğŸ“ˆ Model learns patterns\n",
    "         |\n",
    "         v\n",
    "STEP 4: TEST IT\n",
    "    ğŸ§ª Give new reviews\n",
    "    âœ… Check if predictions are correct\n",
    "         |\n",
    "         v\n",
    "STEP 5: DEPLOY\n",
    "    ğŸš€ Upload to cloud\n",
    "    ğŸŒ Anyone can use it!\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â“ Why Not Train From Scratch?\n",
    "\n",
    "Great question! Let's compare:\n",
    "\n",
    "### ğŸ†š Training From Scratch vs Fine-Tuning\n",
    "\n",
    "| Aspect | Training From Scratch | Fine-Tuning | Winner |\n",
    "|--------|----------------------|-------------|--------|\n",
    "| **Data Needed** | 10+ million examples | 500-5000 examples | Fine-tuning ğŸ† |\n",
    "| **Time Required** | Weeks/Months | Hours/Minutes | Fine-tuning ğŸ† |\n",
    "| **Cost** | $10,000+ | $0-10 | Fine-tuning ğŸ† |\n",
    "| **Expertise Needed** | PhD level | Beginner friendly | Fine-tuning ğŸ† |\n",
    "| **Results** | Uncertain | Usually great | Fine-tuning ğŸ† |\n",
    "\n",
    "### ğŸ’° Real Cost Example:\n",
    "- **From Scratch**: Like building a whole university = $$$$$\n",
    "- **Fine-tuning**: Like a training workshop = $\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Let's Start! First, Install What We Need\n",
    "\n",
    "### ğŸ“¦ Required Libraries Explained:\n",
    "\n",
    "- **transformers**: The magic library from Hugging Face\n",
    "- **datasets**: For handling our data efficiently\n",
    "- **torch**: PyTorch for the actual training\n",
    "- **scikit-learn**: For splitting data and metrics\n",
    "- **accelerate**: Makes training faster\n",
    "\n",
    "Let's install everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ INSTALLATION CELL - Run this first!\n",
    "# This installs all the AI libraries we need\n",
    "\n",
    "print(\"ğŸš€ Starting installation of required packages...\\n\")\n",
    "print(\"This will take about 1-2 minutes...\\n\")\n",
    "\n",
    "# Install transformers - this is the main library for fine-tuning\n",
    "!pip install -q transformers\n",
    "print(\"âœ… Transformers installed - this gives us pre-trained models\")\n",
    "\n",
    "# Install datasets - for efficient data handling\n",
    "!pip install -q datasets\n",
    "print(\"âœ… Datasets installed - for managing our training data\")\n",
    "\n",
    "# Install accelerate - makes training faster\n",
    "!pip install -q accelerate\n",
    "print(\"âœ… Accelerate installed - for faster training\")\n",
    "\n",
    "# Install evaluate - for measuring performance\n",
    "!pip install -q evaluate\n",
    "print(\"âœ… Evaluate installed - to measure how good our model is\")\n",
    "\n",
    "# Install huggingface_hub - for uploading our model\n",
    "!pip install -q huggingface_hub\n",
    "print(\"âœ… Hugging Face Hub installed - for model deployment\")\n",
    "\n",
    "# Install scikit-learn - for data splitting and metrics\n",
    "!pip install -q scikit-learn\n",
    "print(\"âœ… Scikit-learn installed - for data management\")\n",
    "\n",
    "# Install PyTorch with CUDA support for GPU\n",
    "# This is the deep learning framework\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "print(\"âœ… PyTorch installed - the engine that powers everything\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ‰ ALL PACKAGES INSTALLED SUCCESSFULLY!\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nğŸ“ Note: You might see some warnings - that's normal!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Now Let's Import Everything We Need\n",
    "\n",
    "### What Each Import Does:\n",
    "\n",
    "- **pandas**: For handling our data like Excel sheets\n",
    "- **numpy**: For numerical operations\n",
    "- **torch**: The deep learning engine\n",
    "- **transformers**: For loading and training models\n",
    "- **sklearn**: For splitting data and calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š IMPORT CELL - Load all our tools\n",
    "# Each import is explained so you know what it does!\n",
    "\n",
    "print(\"ğŸ“š Importing libraries...\\n\")\n",
    "\n",
    "# Data handling libraries\n",
    "import pandas as pd  # Like Excel for Python\n",
    "import numpy as np   # For numerical operations\n",
    "print(\"âœ… Data libraries imported\")\n",
    "\n",
    "# Deep learning framework\n",
    "import torch  # PyTorch - the engine for our AI\n",
    "print(\"âœ… PyTorch imported\")\n",
    "\n",
    "# Hugging Face transformers - the star of the show!\n",
    "from transformers import (\n",
    "    AutoTokenizer,  # Converts text to numbers\n",
    "    AutoModelForSequenceClassification,  # The actual model\n",
    "    TrainingArguments,  # Settings for training\n",
    "    Trainer,  # The training manager\n",
    "    DataCollatorWithPadding  # Makes all texts same length\n",
    ")\n",
    "print(\"âœ… Transformers components imported\")\n",
    "\n",
    "# Dataset handling\n",
    "from datasets import Dataset, DatasetDict  # Efficient data handling\n",
    "print(\"âœ… Dataset tools imported\")\n",
    "\n",
    "# For splitting data and measuring performance\n",
    "from sklearn.model_selection import train_test_split  # Split data into train/test\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(\"âœ… Scikit-learn tools imported\")\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt  # For creating plots\n",
    "import seaborn as sns  # For pretty visualizations\n",
    "print(\"âœ… Visualization tools imported\")\n",
    "\n",
    "# Ignore warnings to keep output clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"âœ… Warning filter set\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ‰ All libraries imported successfully!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ–¥ï¸ Check If We Have a GPU (Graphics Card)\n",
    "\n",
    "### Why GPU Matters:\n",
    "- **GPU** = Graphics Processing Unit (very fast for AI)\n",
    "- **CPU** = Regular processor (slower for AI)\n",
    "\n",
    "Think of it like:\n",
    "- **GPU**: Like having 1000 workers doing simple tasks = FAST! âš¡\n",
    "- **CPU**: Like having 8 smart workers doing complex tasks = SLOWER ğŸ¢\n",
    "\n",
    "Don't worry if you don't have GPU - it will still work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ–¥ï¸ CHECK HARDWARE CELL - See what computer power we have\n",
    "\n",
    "print(\"ğŸ” Checking available hardware...\\n\")\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # We have a GPU! This is good news\n",
    "    device = torch.device('cuda')\n",
    "    print(\"ğŸ® Great news! GPU is available!\")\n",
    "    print(f\"ğŸ“Š GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(\"\\nâš¡ Training will be FAST!\")\n",
    "    \n",
    "    # Estimate training time\n",
    "    estimated_time = \"5-10 minutes\"\n",
    "else:\n",
    "    # No GPU, we'll use CPU\n",
    "    device = torch.device('cpu')\n",
    "    print(\"ğŸ’» No GPU found - using CPU\")\n",
    "    print(\"â° Training will be slower but will still work!\")\n",
    "    \n",
    "    # Estimate training time\n",
    "    estimated_time = \"15-30 minutes\"\n",
    "\n",
    "print(f\"\\nâ±ï¸ Estimated training time: {estimated_time}\")\n",
    "print(f\"ğŸ“ Device selected: {device}\")\n",
    "\n",
    "# Fun fact about GPUs\n",
    "print(\"\\nğŸ’¡ Fun Fact:\")\n",
    "print(\"GPUs were originally made for video games, but turned out\")\n",
    "print(\"to be perfect for AI because both need lots of parallel processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Understanding Pre-trained Models\n",
    "\n",
    "### ğŸ¤– What Models Can We Choose?\n",
    "\n",
    "Think of these like different types of vehicles:\n",
    "\n",
    "| Model | Size | Speed | Accuracy | Best For | Like a... |\n",
    "|-------|------|-------|----------|----------|----------|\n",
    "| **DistilBERT** | 66M params | âš¡ Very Fast | Good | Quick tests, demos | Sports car ğŸï¸ |\n",
    "| **BERT-base** | 110M params | ğŸƒ Medium | Better | Production use | SUV ğŸš™ |\n",
    "| **RoBERTa** | 125M params | ğŸ¢ Slower | Best | When accuracy matters | Truck ğŸš› |\n",
    "| **ALBERT** | 12M params | âš¡âš¡ Fastest | Okay | Mobile apps | Motorcycle ğŸï¸ |\n",
    "\n",
    "### ğŸ¯ Why We're Using DistilBERT:\n",
    "\n",
    "1. **Fast** - Perfect for our 2-hour session\n",
    "2. **Good Performance** - 97% as good as BERT\n",
    "3. **Small** - Fits in Google Colab free tier\n",
    "4. **Easy** - Simple to understand\n",
    "\n",
    "### ğŸ“ What Does \"66M Parameters\" Mean?\n",
    "\n",
    "Parameters are like brain cells:\n",
    "- More parameters = Smarter but slower\n",
    "- 66 million = 66,000,000 adjustable values\n",
    "- Each one learns something about language!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¬ Part 2: Let's Build Our Movie Sentiment Analyzer!\n",
    "\n",
    "## Now the fun begins - hands-on time!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 1: Load Our Movie Review Data\n",
    "\n",
    "### What We're Loading:\n",
    "- **IMDB Dataset**: 50,000 movie reviews\n",
    "- **Labels**: Positive or Negative sentiment\n",
    "- **Goal**: Teach our model to understand movie opinions\n",
    "\n",
    "### Data Loading Priority:\n",
    "1. First try: Load cleaned data from previous session\n",
    "2. Second try: Load original IMDB data\n",
    "3. Fallback: Create sample data for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š DATA LOADING CELL - Get our movie reviews ready\n",
    "\n",
    "print(\"ğŸ“‚ Loading movie review data...\\n\")\n",
    "\n",
    "# We'll try three different ways to get data\n",
    "data_loaded = False\n",
    "\n",
    "# ATTEMPT 1: Try to load cleaned data from previous session\n",
    "try:\n",
    "    df = pd.read_csv('/content/IMDB_cleaned.csv')\n",
    "    print(\"âœ… Excellent! Found cleaned data from data cleaning session!\")\n",
    "    print(\"   This data is already preprocessed and ready.\")\n",
    "    text_column = 'cleaned_review'  # Use the cleaned text column\n",
    "    data_loaded = True\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ No cleaned data found, trying original dataset...\")\n",
    "\n",
    "# ATTEMPT 2: Try to load original IMDB dataset\n",
    "if not data_loaded:\n",
    "    try:\n",
    "        df = pd.read_csv('/content/IMDB Dataset.csv')\n",
    "        print(\"âœ… Found original IMDB dataset!\")\n",
    "        print(\"   Note: Using raw reviews (not cleaned)\")\n",
    "        text_column = 'review'  # Use the raw review column\n",
    "        data_loaded = True\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ No IMDB dataset found either...\")\n",
    "\n",
    "# ATTEMPT 3: Create sample data for demonstration\n",
    "if not data_loaded:\n",
    "    print(\"âš ï¸ Creating sample data for demonstration...\")\n",
    "    print(\"   (Upload 'IMDB Dataset.csv' for real training)\\n\")\n",
    "    \n",
    "    # Create diverse sample reviews\n",
    "    positive_reviews = [\n",
    "        \"This movie was absolutely fantastic! Best film I've seen all year!\",\n",
    "        \"Amazing cinematography and brilliant acting. A masterpiece!\",\n",
    "        \"I loved every minute of it. Highly recommend to everyone!\",\n",
    "        \"Outstanding performance by the lead actor. Oscar-worthy!\",\n",
    "        \"The story was captivating from start to finish. Brilliant!\",\n",
    "        \"One of the best movies ever made. Simply perfect!\",\n",
    "        \"Incredible visual effects and great storyline!\",\n",
    "        \"This film touched my heart. Beautiful and moving.\",\n",
    "    ]\n",
    "    \n",
    "    negative_reviews = [\n",
    "        \"Terrible movie. Complete waste of time and money.\",\n",
    "        \"Boring plot and awful acting. Fell asleep halfway through.\",\n",
    "        \"Worst movie I've ever seen. Don't waste your time.\",\n",
    "        \"Poor character development and predictable story.\",\n",
    "        \"The dialogue was cringe-worthy. Couldn't finish it.\",\n",
    "        \"Disappointing. Expected much better from this director.\",\n",
    "        \"Slow pacing and confusing plot. Not recommended.\",\n",
    "        \"Acting was wooden and story made no sense.\",\n",
    "    ]\n",
    "    \n",
    "    # Combine and repeat to have more samples\n",
    "    all_reviews = []\n",
    "    all_sentiments = []\n",
    "    \n",
    "    # Repeat each review to create a larger dataset\n",
    "    for _ in range(50):  # Repeat 50 times\n",
    "        all_reviews.extend(positive_reviews)\n",
    "        all_reviews.extend(negative_reviews)\n",
    "        all_sentiments.extend(['positive'] * len(positive_reviews))\n",
    "        all_sentiments.extend(['negative'] * len(negative_reviews))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'review': all_reviews,\n",
    "        'sentiment': all_sentiments\n",
    "    })\n",
    "    text_column = 'review'\n",
    "    print(f\"âœ… Created {len(df)} sample reviews for demonstration\")\n",
    "\n",
    "# Display dataset information\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š DATASET INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total reviews: {len(df):,}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Text column being used: '{text_column}'\")\n",
    "\n",
    "# Show sentiment distribution\n",
    "print(\"\\nğŸ­ Sentiment Distribution:\")\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {sentiment}: {count:,} reviews ({percentage:.1f}%)\")\n",
    "\n",
    "# Show sample reviews\n",
    "print(\"\\nğŸ“ Sample Reviews:\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(min(3, len(df))):\n",
    "    review_text = df.iloc[i][text_column]\n",
    "    sentiment = df.iloc[i]['sentiment']\n",
    "    # Show first 80 characters of each review\n",
    "    display_text = review_text[:80] + \"...\" if len(review_text) > 80 else review_text\n",
    "    print(f\"Review {i+1} ({sentiment}): {display_text}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¢ Convert Sentiments to Numbers\n",
    "\n",
    "### Why Convert to Numbers?\n",
    "\n",
    "Computers don't understand \"positive\" or \"negative\" - they only understand numbers!\n",
    "\n",
    "So we convert:\n",
    "- **\"negative\"** â†’ 0\n",
    "- **\"positive\"** â†’ 1\n",
    "\n",
    "It's like translating English to Computer language! ğŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¢ LABEL CONVERSION CELL - Convert sentiments to numbers\n",
    "\n",
    "print(\"ğŸ”„ Converting sentiments to numerical labels...\\n\")\n",
    "\n",
    "# Create a mapping: negative=0, positive=1\n",
    "label_mapping = {\n",
    "    'negative': 0,\n",
    "    'positive': 1\n",
    "}\n",
    "\n",
    "# Apply the mapping to create a new 'label' column\n",
    "df['label'] = df['sentiment'].map(label_mapping)\n",
    "\n",
    "# Verify the conversion worked\n",
    "print(\"âœ… Conversion complete!\\n\")\n",
    "print(\"ğŸ“Š Label Mapping:\")\n",
    "print(\"  'negative' â†’ 0\")\n",
    "print(\"  'positive' â†’ 1\")\n",
    "\n",
    "# Show example of the conversion\n",
    "print(\"\\nğŸ“ Example of conversion:\")\n",
    "print(\"-\" * 50)\n",
    "sample_df = df[['sentiment', 'label']].head(5)\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"  {row['sentiment']} â†’ {row['label']}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check for any issues\n",
    "if df['label'].isna().any():\n",
    "    print(\"\\nâš ï¸ Warning: Some labels couldn't be converted!\")\n",
    "    print(f\"   Missing labels: {df['label'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"\\nâœ… All sentiments successfully converted to numbers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‰ Select a Sample for Faster Training\n",
    "\n",
    "### Why Use a Sample?\n",
    "\n",
    "For learning purposes, we'll use a smaller sample:\n",
    "- **Full dataset**: 50,000 reviews â†’ Hours of training\n",
    "- **Our sample**: 2,000 reviews â†’ Minutes of training\n",
    "\n",
    "In real production, you'd use all the data!\n",
    "\n",
    "### The Tradeoff:\n",
    "- **More Data** = Better accuracy but slower\n",
    "- **Less Data** = Faster but slightly less accurate\n",
    "\n",
    "For learning, fast is better! âš¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‰ SAMPLING CELL - Take a subset for faster training\n",
    "\n",
    "print(\"ğŸ“Š Preparing data sample for training...\\n\")\n",
    "\n",
    "# Decide how many samples to use\n",
    "# You can change this number!\n",
    "SAMPLE_SIZE = min(2000, len(df))  # Use 2000 or all data if less than 2000\n",
    "\n",
    "print(f\"Original dataset size: {len(df):,} reviews\")\n",
    "print(f\"Sample size for training: {SAMPLE_SIZE:,} reviews\")\n",
    "print(f\"Sampling ratio: {(SAMPLE_SIZE/len(df)*100):.1f}%\\n\")\n",
    "\n",
    "# Take a random sample, ensuring balanced sentiments\n",
    "# random_state=42 ensures reproducible results\n",
    "df_sample = df.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "\n",
    "# Check the balance of our sample\n",
    "positive_count = (df_sample['label'] == 1).sum()\n",
    "negative_count = (df_sample['label'] == 0).sum()\n",
    "\n",
    "print(\"ğŸ­ Sample Distribution:\")\n",
    "print(f\"  Positive reviews: {positive_count} ({positive_count/SAMPLE_SIZE*100:.1f}%)\")\n",
    "print(f\"  Negative reviews: {negative_count} ({negative_count/SAMPLE_SIZE*100:.1f}%)\")\n",
    "\n",
    "# Check if balanced\n",
    "balance_ratio = min(positive_count, negative_count) / max(positive_count, negative_count)\n",
    "if balance_ratio > 0.8:\n",
    "    print(\"\\nâœ… Good balance! The sample has similar amounts of positive and negative.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Sample is imbalanced. Model might be biased.\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_reviews = df_sample[text_column].isna().sum()\n",
    "if missing_reviews > 0:\n",
    "    print(f\"\\nâš ï¸ Found {missing_reviews} missing reviews. Removing them...\")\n",
    "    df_sample = df_sample.dropna(subset=[text_column])\n",
    "    print(f\"âœ… Cleaned! Final sample size: {len(df_sample)}\")\n",
    "else:\n",
    "    print(\"\\nâœ… No missing values found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"ğŸ“Š Final sample ready: {len(df_sample)} reviews\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”ª Step 2: Split Data into Training and Testing Sets\n",
    "\n",
    "### Why Split the Data?\n",
    "\n",
    "Imagine you're teaching someone math:\n",
    "1. **Training Set (80%)**: Problems they study and practice with\n",
    "2. **Test Set (20%)**: New problems for the final exam\n",
    "\n",
    "We need to test on NEW data the model hasn't seen!\n",
    "\n",
    "### The Split:\n",
    "```\n",
    "All Data (100%)\n",
    "    |\n",
    "    â”œâ”€â”€ Training Set (80%) - For learning\n",
    "    |\n",
    "    â””â”€â”€ Test Set (20%) - For evaluation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”ª DATA SPLITTING CELL - Divide into train and test\n",
    "\n",
    "print(\"âœ‚ï¸ Splitting data into training and testing sets...\\n\")\n",
    "\n",
    "# Extract texts and labels from our sample\n",
    "texts = df_sample[text_column].tolist()  # Convert to list\n",
    "labels = df_sample['label'].tolist()      # Convert to list\n",
    "\n",
    "print(f\"Total texts: {len(texts)}\")\n",
    "print(f\"Total labels: {len(labels)}\\n\")\n",
    "\n",
    "# Split the data: 80% for training, 20% for testing\n",
    "# stratify ensures both sets have same ratio of positive/negative\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts,                # Our review texts\n",
    "    labels,               # Our labels (0 or 1)\n",
    "    test_size=0.2,        # 20% for testing\n",
    "    random_state=42,      # For reproducible results\n",
    "    stratify=labels       # Keep same positive/negative ratio\n",
    ")\n",
    "\n",
    "# Display the split results\n",
    "print(\"ğŸ“Š DATA SPLIT COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nğŸ‹ï¸ TRAINING SET:\")\n",
    "print(f\"  Total samples: {len(train_texts)}\")\n",
    "print(f\"  Positive reviews: {sum(train_labels)} ({sum(train_labels)/len(train_labels)*100:.1f}%)\")\n",
    "print(f\"  Negative reviews: {len(train_labels) - sum(train_labels)} ({(len(train_labels) - sum(train_labels))/len(train_labels)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nğŸ§ª TEST SET:\")\n",
    "print(f\"  Total samples: {len(test_texts)}\")\n",
    "print(f\"  Positive reviews: {sum(test_labels)} ({sum(test_labels)/len(test_labels)*100:.1f}%)\")\n",
    "print(f\"  Negative reviews: {len(test_labels) - sum(test_labels)} ({(len(test_labels) - sum(test_labels))/len(test_labels)*100:.1f}%)\")\n",
    "\n",
    "# Show example from each set\n",
    "print(\"\\nğŸ“ Example from TRAINING set:\")\n",
    "print(f\"  Text: \\\"{train_texts[0][:100]}...\\\"\")\n",
    "print(f\"  Label: {train_labels[0]} ({'positive' if train_labels[0] == 1 else 'negative'})\")\n",
    "\n",
    "print(\"\\nğŸ“ Example from TEST set:\")\n",
    "print(f\"  Text: \\\"{test_texts[0][:100]}...\\\"\")\n",
    "print(f\"  Label: {test_labels[0]} ({'positive' if test_labels[0] == 1 else 'negative'})\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Remember: The model will NEVER see the test set during training!\")\n",
    "print(\"   We keep it hidden to fairly evaluate performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Visualize the Data Split\n",
    "\n",
    "Let's see our data split visually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š VISUALIZATION CELL - Show the split graphically\n",
    "\n",
    "print(\"ğŸ“Š Creating visualization of data split...\\n\")\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Define colors\n",
    "colors = ['#e74c3c', '#2ecc71']  # Red for negative, Green for positive\n",
    "\n",
    "# Plot 1: Overall split\n",
    "split_sizes = [len(train_texts), len(test_texts)]\n",
    "axes[0].pie(split_sizes, labels=['Train (80%)', 'Test (20%)'], \n",
    "            autopct='%1.0f%%', colors=['#3498db', '#9b59b6'],\n",
    "            startangle=90)\n",
    "axes[0].set_title('Overall Data Split', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot 2: Training set distribution\n",
    "train_pos = sum(train_labels)\n",
    "train_neg = len(train_labels) - train_pos\n",
    "axes[1].pie([train_neg, train_pos], labels=['Negative', 'Positive'],\n",
    "            autopct='%1.0f%%', colors=colors, startangle=90)\n",
    "axes[1].set_title('Training Set Sentiment', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot 3: Test set distribution  \n",
    "test_pos = sum(test_labels)\n",
    "test_neg = len(test_labels) - test_pos\n",
    "axes[2].pie([test_neg, test_pos], labels=['Negative', 'Positive'],\n",
    "            autopct='%1.0f%%', colors=colors, startangle=90)\n",
    "axes[2].set_title('Test Set Sentiment', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('ğŸ“Š Data Split Visualization', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Visualization complete!\")\n",
    "print(\"ğŸ“ Note: Both sets have similar sentiment distributions - this is good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Step 3: Load the Pre-trained Model\n",
    "\n",
    "### What's Happening Here?\n",
    "\n",
    "We're downloading a model that already knows English!\n",
    "\n",
    "Think of it like:\n",
    "1. **Hiring an English teacher** (pre-trained model)\n",
    "2. **Teaching them about movies** (fine-tuning)\n",
    "3. **They become a movie critic** (specialized model)\n",
    "\n",
    "### Model Components:\n",
    "\n",
    "1. **Tokenizer**: Converts text â†’ numbers\n",
    "   - \"great movie\" â†’ [2307, 3185]\n",
    "   \n",
    "2. **Model**: The actual brain\n",
    "   - Takes numbers, outputs predictions\n",
    "\n",
    "Let's load them! ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– MODEL LOADING CELL - Download and prepare the pre-trained model\n",
    "\n",
    "print(\"ğŸ¤– LOADING PRE-TRAINED MODEL\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Choose which model to use\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "print(f\"ğŸ“¦ Model selected: {MODEL_NAME}\")\n",
    "print(\"\\nğŸ“ About this model:\")\n",
    "print(\"  - Created by: Hugging Face\")\n",
    "print(\"  - Size: ~250 MB\")\n",
    "print(\"  - Parameters: 66 million\")\n",
    "print(\"  - Language: English\")\n",
    "print(\"  - Special: 40% smaller than BERT, 97% as good!\")\n",
    "\n",
    "print(\"\\nâ¬‡ï¸ Downloading model components...\")\n",
    "print(\"  (This may take 1-2 minutes on first run)\\n\")\n",
    "\n",
    "# STEP 1: Load the tokenizer\n",
    "print(\"ğŸ“ Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(\"âœ… Tokenizer loaded successfully!\")\n",
    "print(f\"   Vocabulary size: {tokenizer.vocab_size:,} words\")\n",
    "\n",
    "# STEP 2: Load the model\n",
    "print(\"\\nğŸ§  Loading model...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,  # We have 2 classes: positive and negative\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},  # Map numbers to labels\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1}   # Map labels to numbers\n",
    ")\n",
    "print(\"âœ… Model loaded successfully!\")\n",
    "\n",
    "# STEP 3: Move model to appropriate device (GPU or CPU)\n",
    "print(f\"\\nğŸš€ Moving model to {device}...\")\n",
    "model = model.to(device)\n",
    "print(f\"âœ… Model is now on {device}\")\n",
    "\n",
    "# Calculate model statistics\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nğŸ“Š MODEL STATISTICS:\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"Model size in memory: ~{total_params * 4 / 1024**2:.1f} MB\")\n",
    "\n",
    "print(\"\\nâœ¨ Model is ready for fine-tuning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¤ Understanding Tokenization\n",
    "\n",
    "### What is Tokenization?\n",
    "\n",
    "Computers don't understand words - only numbers! Tokenization converts:\n",
    "\n",
    "```\n",
    "\"This movie is great!\" \n",
    "         â†“\n",
    "[101, 2023, 3185, 2003, 2307, 999, 102]\n",
    "```\n",
    "\n",
    "Each number represents a word or part of a word:\n",
    "- 101 = [START]\n",
    "- 2023 = \"this\"\n",
    "- 3185 = \"movie\"\n",
    "- 2003 = \"is\"\n",
    "- 2307 = \"great\"\n",
    "- 999 = \"!\"\n",
    "- 102 = [END]\n",
    "\n",
    "Let's see it in action! ğŸ‘€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¤ TOKENIZATION DEMO CELL - See how text becomes numbers\n",
    "\n",
    "print(\"ğŸ”¤ TOKENIZATION DEMONSTRATION\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example sentences to tokenize\n",
    "example_sentences = [\n",
    "    \"This movie is amazing!\",\n",
    "    \"Terrible film\",\n",
    "    \"ğŸ˜ Best movie ever!!! #MustWatch\"\n",
    "]\n",
    "\n",
    "print(\"Let's see how the tokenizer converts text to numbers:\\n\")\n",
    "\n",
    "for i, sentence in enumerate(example_sentences, 1):\n",
    "    print(f\"Example {i}: \\\"{sentence}\\\"\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Tokenize the sentence\n",
    "    tokens = tokenizer(\n",
    "        sentence,\n",
    "        padding=True,      # Add padding if needed\n",
    "        truncation=True,   # Cut if too long\n",
    "        return_tensors='pt'  # Return PyTorch tensors\n",
    "    )\n",
    "    \n",
    "    # Get the token IDs\n",
    "    token_ids = tokens['input_ids'][0].tolist()\n",
    "    \n",
    "    # Decode each token\n",
    "    print(\"  Token breakdown:\")\n",
    "    for token_id in token_ids:\n",
    "        word = tokenizer.decode([token_id])\n",
    "        # Clean up special tokens for display\n",
    "        if word in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "            print(f\"    {token_id:5d} â†’ {word} (special token)\")\n",
    "        else:\n",
    "            print(f\"    {token_id:5d} â†’ '{word}'\")\n",
    "    \n",
    "    print(f\"\\n  Total tokens: {len(token_ids)}\")\n",
    "    print(f\"  Full decoded: \\\"{tokenizer.decode(token_ids)}\\\"\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ Note: [CLS] = start, [SEP] = end, [PAD] = padding\")\n",
    "print(\"   These special tokens help the model understand structure!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¢ Step 4: Tokenize All Our Data\n",
    "\n",
    "### Now Let's Convert ALL Our Reviews!\n",
    "\n",
    "We need to tokenize:\n",
    "- Training reviews â†’ numbers for learning\n",
    "- Test reviews â†’ numbers for evaluation\n",
    "\n",
    "### Important Settings:\n",
    "- **max_length=256**: Maximum tokens per review\n",
    "  - Too short = lose information\n",
    "  - Too long = slow training\n",
    "- **padding=True**: Make all reviews same length\n",
    "- **truncation=True**: Cut reviews that are too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¢ TOKENIZATION CELL - Convert all texts to numbers\n",
    "\n",
    "print(\"ğŸ”„ TOKENIZING ALL DATA\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_function(texts):\n",
    "    \"\"\"\n",
    "    Convert texts to tokens that the model can understand.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of review texts\n",
    "    Returns:\n",
    "        Dictionary with input_ids and attention_mask\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,      # Add padding to make all same length\n",
    "        truncation=True,   # Cut texts that are too long\n",
    "        max_length=256     # Maximum length (in tokens)\n",
    "    )\n",
    "\n",
    "# TOKENIZE TRAINING DATA\n",
    "print(\"ğŸ“ Tokenizing training data...\")\n",
    "print(f\"   Processing {len(train_texts)} reviews...\")\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "print(\"âœ… Training data tokenized!\")\n",
    "print(f\"   Shape: {len(train_encodings['input_ids'])} reviews\")\n",
    "print(f\"   Max length: {len(train_encodings['input_ids'][0])} tokens\\n\")\n",
    "\n",
    "# TOKENIZE TEST DATA\n",
    "print(\"ğŸ“ Tokenizing test data...\")\n",
    "print(f\"   Processing {len(test_texts)} reviews...\")\n",
    "test_encodings = tokenize_function(test_texts)\n",
    "print(\"âœ… Test data tokenized!\")\n",
    "print(f\"   Shape: {len(test_encodings['input_ids'])} reviews\")\n",
    "print(f\"   Max length: {len(test_encodings['input_ids'][0])} tokens\\n\")\n",
    "\n",
    "# Show what the tokenizer created\n",
    "print(\"ğŸ“Š What the tokenizer created:\")\n",
    "print(\"  1. input_ids: The token numbers\")\n",
    "print(\"  2. attention_mask: Which tokens to pay attention to\")\n",
    "print(\"     (1 = real token, 0 = padding)\\n\")\n",
    "\n",
    "# Example of tokenized data\n",
    "print(\"ğŸ“ Example of tokenized review:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Original: \\\"{train_texts[0][:100]}...\\\"\")\n",
    "print(f\"\\nTokenized (first 20 tokens):\")\n",
    "print(f\"  {train_encodings['input_ids'][0][:20]}\")\n",
    "print(f\"\\nAttention mask (first 20):\")\n",
    "print(f\"  {train_encodings['attention_mask'][0][:20]}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nâœ¨ All data successfully tokenized and ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Create Dataset Objects\n",
    "\n",
    "### Why Dataset Objects?\n",
    "\n",
    "The Hugging Face library needs data in a special format.\n",
    "Think of it like packaging your data in the right box for shipping! ğŸ“¦\n",
    "\n",
    "Each dataset contains:\n",
    "- **input_ids**: The tokenized text\n",
    "- **attention_mask**: Which parts to focus on\n",
    "- **labels**: The correct answers (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ DATASET CREATION CELL - Package data for training\n",
    "\n",
    "print(\"ğŸ“¦ Creating Dataset Objects\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create training dataset\n",
    "print(\"ğŸ‹ï¸ Creating training dataset...\")\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'],        # The tokenized text\n",
    "    'attention_mask': train_encodings['attention_mask'],  # What to pay attention to\n",
    "    'labels': train_labels                            # The correct answers\n",
    "})\n",
    "print(f\"âœ… Training dataset created with {len(train_dataset)} samples\")\n",
    "\n",
    "# Create test dataset\n",
    "print(\"\\nğŸ§ª Creating test dataset...\")\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask'],\n",
    "    'labels': test_labels\n",
    "})\n",
    "print(f\"âœ… Test dataset created with {len(test_dataset)} samples\")\n",
    "\n",
    "# Show dataset structure\n",
    "print(\"\\nğŸ“Š Dataset Structure:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Each sample contains:\")\n",
    "print(\"  â€¢ input_ids: Token numbers\")\n",
    "print(\"  â€¢ attention_mask: Focus indicators\")\n",
    "print(\"  â€¢ labels: Correct sentiment (0 or 1)\")\n",
    "\n",
    "# Show an example from the dataset\n",
    "print(\"\\nğŸ“ Example from training dataset:\")\n",
    "print(\"-\" * 40)\n",
    "sample = train_dataset[0]\n",
    "print(f\"Label: {sample['labels']} ({'POSITIVE' if sample['labels'] == 1 else 'NEGATIVE'})\")\n",
    "print(f\"Input IDs (first 10): {sample['input_ids'][:10]}...\")\n",
    "print(f\"Attention (first 10): {sample['attention_mask'][:10]}...\")\n",
    "\n",
    "print(\"\\nâœ… Datasets are ready for training!\")\n",
    "print(\"   These will be fed to the model during training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Step 5: Configure Training Settings\n",
    "\n",
    "### ğŸ›ï¸ Training Parameters Explained:\n",
    "\n",
    "Think of these like recipe instructions:\n",
    "\n",
    "| Parameter | What it means | Our Value | Analogy |\n",
    "|-----------|---------------|-----------|----------|\n",
    "| **Epochs** | How many times to see all data | 3 | Reading a book 3 times |\n",
    "| **Batch Size** | Samples processed together | 16 | Students in a class |\n",
    "| **Learning Rate** | How fast to learn | 2e-5 | Walking speed vs running |\n",
    "| **Warmup Steps** | Gentle start | 500 | Stretching before exercise |\n",
    "\n",
    "### ğŸ“Š What Happens During Training:\n",
    "\n",
    "```\n",
    "Epoch 1: See all data once â†’ Learn basics\n",
    "Epoch 2: See all data again â†’ Improve understanding  \n",
    "Epoch 3: See all data again â†’ Perfect the knowledge\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ TRAINING CONFIGURATION CELL - Set all training parameters\n",
    "\n",
    "print(\"âš™ï¸ CONFIGURING TRAINING PARAMETERS\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define all training arguments\n",
    "training_args = TrainingArguments(\n",
    "    # WHERE TO SAVE\n",
    "    output_dir='./results',              # Where to save model checkpoints\n",
    "    \n",
    "    # TRAINING SETTINGS\n",
    "    num_train_epochs=3,                  # How many times to see all data\n",
    "    per_device_train_batch_size=16,      # How many samples to process together\n",
    "    per_device_eval_batch_size=32,       # Batch size for evaluation (can be larger)\n",
    "    \n",
    "    # LEARNING SETTINGS\n",
    "    warmup_steps=500,                    # Steps for gradual learning rate increase\n",
    "    weight_decay=0.01,                   # Regularization to prevent overfitting\n",
    "    learning_rate=2e-5,                  # How fast to learn (0.00002)\n",
    "    \n",
    "    # LOGGING SETTINGS\n",
    "    logging_dir='./logs',                # Where to save training logs\n",
    "    logging_steps=10,                    # Log every 10 steps\n",
    "    \n",
    "    # EVALUATION SETTINGS\n",
    "    evaluation_strategy=\"epoch\",         # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",                # Save model after each epoch\n",
    "    \n",
    "    # BEST MODEL SETTINGS\n",
    "    load_best_model_at_end=True,         # Load the best model at the end\n",
    "    metric_for_best_model=\"eval_loss\",   # What metric to use for \"best\"\n",
    "    greater_is_better=False,              # Lower loss is better\n",
    "    \n",
    "    # OTHER SETTINGS\n",
    "    push_to_hub=False,                   # Don't auto-upload (we'll do manually)\n",
    "    report_to=\"none\",                    # Don't use tracking tools\n",
    ")\n",
    "\n",
    "# Calculate training statistics\n",
    "total_training_steps = len(train_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "\n",
    "print(\"ğŸ“Š TRAINING CONFIGURATION SUMMARY:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"ğŸ“š Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"ğŸ“¦ Batch size: {training_args.per_device_train_batch_size} samples\")\n",
    "print(f\"ğŸ¯ Learning rate: {training_args.learning_rate} (0.00002)\")\n",
    "print(f\"ğŸ”¥ Warmup steps: {training_args.warmup_steps}\")\n",
    "print(f\"ğŸ“ˆ Total training steps: ~{total_training_steps}\")\n",
    "\n",
    "print(\"\\nâ±ï¸ ESTIMATED TRAINING TIME:\")\n",
    "if device.type == 'cuda':\n",
    "    estimated_time = total_training_steps * 0.5 / 60  # ~0.5 seconds per step on GPU\n",
    "    print(f\"  With GPU: ~{estimated_time:.1f} minutes\")\n",
    "else:\n",
    "    estimated_time = total_training_steps * 2 / 60  # ~2 seconds per step on CPU\n",
    "    print(f\"  With CPU: ~{estimated_time:.1f} minutes\")\n",
    "\n",
    "print(\"\\nğŸ’¾ SAVING STRATEGY:\")\n",
    "print(f\"  Model will be saved after each epoch to: {training_args.output_dir}\")\n",
    "print(f\"  Best model will be selected based on: {training_args.metric_for_best_model}\")\n",
    "\n",
    "print(\"\\nâœ… Training configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 6: Define How to Measure Success\n",
    "\n",
    "### Metrics We'll Track:\n",
    "\n",
    "1. **Accuracy**: What percentage did we get right?\n",
    "   - Example: 90% = 9 out of 10 correct\n",
    "   \n",
    "2. **Loss**: How wrong were our predictions?\n",
    "   - Lower is better\n",
    "   - Like a golf score!\n",
    "\n",
    "### Success Criteria:\n",
    "- **Excellent**: >90% accuracy\n",
    "- **Good**: 80-90% accuracy\n",
    "- **Okay**: 70-80% accuracy\n",
    "- **Needs work**: <70% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ METRICS CELL - Define how to measure model performance\n",
    "\n",
    "print(\"ğŸ“ DEFINING EVALUATION METRICS\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Calculate metrics to evaluate model performance.\n",
    "    \n",
    "    Args:\n",
    "        eval_pred: Contains predictions and true labels\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with calculated metrics\n",
    "    \"\"\"\n",
    "    # Extract predictions and labels\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Get the predicted class (highest probability)\n",
    "    # predictions shape: (num_samples, 2) - probabilities for each class\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    # Return metrics\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "\n",
    "print(\"âœ… Metrics function defined!\\n\")\n",
    "\n",
    "print(\"ğŸ“Š Metrics we'll track during training:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"1. ACCURACY:\")\n",
    "print(\"   â€¢ What it measures: Percentage of correct predictions\")\n",
    "print(\"   â€¢ Range: 0% to 100%\")\n",
    "print(\"   â€¢ Goal: As high as possible!\")\n",
    "print(\"\\n2. LOSS:\")\n",
    "print(\"   â€¢ What it measures: How wrong the predictions are\")\n",
    "print(\"   â€¢ Range: 0 to infinity\")\n",
    "print(\"   â€¢ Goal: As low as possible!\")\n",
    "\n",
    "print(\"\\nğŸ¯ Success Benchmarks:\")\n",
    "print(\"   >95% accuracy = ğŸ† Outstanding!\")\n",
    "print(\"   90-95% = ğŸ‰ Excellent\")\n",
    "print(\"   85-90% = ğŸ˜Š Very Good\")\n",
    "print(\"   80-85% = ğŸ‘ Good\")\n",
    "print(\"   <80% = ğŸ“ˆ Room for improvement\")\n",
    "\n",
    "print(\"\\nâœ… Ready to evaluate model performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 7: Create the Trainer\n",
    "\n",
    "### What is the Trainer?\n",
    "\n",
    "The Trainer is like a personal coach for your model:\n",
    "- ğŸ“š Shows training examples\n",
    "- ğŸ“ Tests understanding\n",
    "- ğŸ“ˆ Tracks progress\n",
    "- ğŸ’¾ Saves best version\n",
    "- ğŸ¯ Optimizes learning\n",
    "\n",
    "It handles all the complex training logic for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ TRAINER CREATION CELL - Set up the training manager\n",
    "\n",
    "print(\"ğŸ“ CREATING THE TRAINER\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"ğŸ“¦ Assembling all components...\\n\")\n",
    "\n",
    "# Create the Trainer with all our components\n",
    "trainer = Trainer(\n",
    "    model=model,                          # Our DistilBERT model\n",
    "    args=training_args,                   # Training configuration\n",
    "    train_dataset=train_dataset,          # Training data\n",
    "    eval_dataset=test_dataset,            # Test data for evaluation\n",
    "    tokenizer=tokenizer,                  # Tokenizer for processing text\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),  # Handles padding\n",
    "    compute_metrics=compute_metrics,      # Our metrics function\n",
    ")\n",
    "\n",
    "print(\"âœ… Trainer successfully created!\\n\")\n",
    "\n",
    "print(\"ğŸ“Š TRAINER CONFIGURATION:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"ğŸ¤– Model: {MODEL_NAME}\")\n",
    "print(f\"ğŸ“š Training samples: {len(train_dataset)}\")\n",
    "print(f\"ğŸ§ª Test samples: {len(test_dataset)}\")\n",
    "print(f\"ğŸ”„ Epochs to train: {training_args.num_train_epochs}\")\n",
    "print(f\"ğŸ“¦ Batch size: {training_args.per_device_train_batch_size}\")\n",
    "\n",
    "print(\"\\nğŸ¯ What the Trainer will do:\")\n",
    "print(\"  1. Show model training examples\")\n",
    "print(\"  2. Calculate how wrong predictions are\")\n",
    "print(\"  3. Adjust model to improve\")\n",
    "print(\"  4. Repeat for all epochs\")\n",
    "print(\"  5. Save best version\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ READY TO START FINE-TUNING!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâ±ï¸ Training will begin in the next cell...\")\n",
    "print(\"â˜• This is a good time to grab coffee!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 8: FINE-TUNE THE MODEL!\n",
    "\n",
    "### This is the Main Event! ğŸ¯\n",
    "\n",
    "What happens during training:\n",
    "1. **Epoch 1**: Model sees all data once, starts learning patterns\n",
    "2. **Epoch 2**: Reinforces learning, improves accuracy\n",
    "3. **Epoch 3**: Fine-tunes understanding, perfects predictions\n",
    "\n",
    "Watch the loss go down and accuracy go up! ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ TRAINING CELL - Fine-tune the model!\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"ğŸš€ STARTING FINE-TUNING PROCESS!\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“š Training Details:\")\n",
    "print(f\"  â€¢ Model: {MODEL_NAME}\")\n",
    "print(f\"  â€¢ Training samples: {len(train_dataset)}\")\n",
    "print(f\"  â€¢ Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  â€¢ Device: {device}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nâ±ï¸ Starting timer...\")\n",
    "print(\"ğŸ”„ Training in progress...\\n\")\n",
    "print(\"You'll see updates every few steps:\")\n",
    "print(\"  â€¢ loss = how wrong the model is (lower is better)\")\n",
    "print(\"  â€¢ learning_rate = how fast we're learning\")\n",
    "print(\"  â€¢ epoch = which round of training\\n\")\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# START TRAINING!\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Calculate training duration\n",
    "training_time = time.time() - start_time\n",
    "minutes = int(training_time // 60)\n",
    "seconds = int(training_time % 60)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ FINE-TUNING COMPLETE! ğŸ‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nğŸ“Š TRAINING SUMMARY:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"â±ï¸ Total time: {minutes} minutes {seconds} seconds\")\n",
    "print(f\"ğŸ“‰ Final training loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"ğŸ“ˆ Total steps: {train_result.global_step}\")\n",
    "print(f\"ğŸ”„ Epochs completed: {training_args.num_train_epochs}\")\n",
    "\n",
    "# Performance interpretation\n",
    "if train_result.training_loss < 0.3:\n",
    "    print(\"\\nâœ¨ Excellent! Very low loss - model learned well!\")\n",
    "elif train_result.training_loss < 0.5:\n",
    "    print(\"\\nğŸ‘ Good! Reasonable loss - model is performing well!\")\n",
    "else:\n",
    "    print(\"\\nğŸ“ˆ Model trained, but might benefit from more epochs!\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Model checkpoints saved to: ./results\")\n",
    "print(\"ğŸ¯ Best model automatically selected based on validation loss!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Step 9: Evaluate Model Performance\n",
    "\n",
    "### Time to Test Our Model! ğŸ¯\n",
    "\n",
    "Now we test on data the model has NEVER seen before.\n",
    "This is the real test - like a final exam!\n",
    "\n",
    "We'll check:\n",
    "- **Accuracy**: How many did we get right?\n",
    "- **Confusion Matrix**: Where did we make mistakes?\n",
    "- **Classification Report**: Detailed performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª EVALUATION CELL - Test the model's performance\n",
    "\n",
    "print(\"ğŸ§ª EVALUATING MODEL PERFORMANCE\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"Testing on unseen data...\\n\")\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Display results\n",
    "print(\"ğŸ“Š EVALUATION RESULTS:\")\n",
    "print(\"=\"*40)\n",
    "print(f\"âœ… Accuracy: {eval_results['eval_accuracy']*100:.2f}%\")\n",
    "print(f\"ğŸ“‰ Loss: {eval_results['eval_loss']:.4f}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Interpret the results\n",
    "accuracy_percent = eval_results['eval_accuracy'] * 100\n",
    "\n",
    "print(\"\\nğŸ¯ PERFORMANCE INTERPRETATION:\")\n",
    "if accuracy_percent >= 95:\n",
    "    print(f\"ğŸ† OUTSTANDING! {accuracy_percent:.1f}% accuracy is exceptional!\")\n",
    "    print(\"   Your model is performing at professional level!\")\n",
    "elif accuracy_percent >= 90:\n",
    "    print(f\"ğŸ‰ EXCELLENT! {accuracy_percent:.1f}% accuracy is very impressive!\")\n",
    "    print(\"   Your model is ready for production use!\")\n",
    "elif accuracy_percent >= 85:\n",
    "    print(f\"ğŸ˜Š VERY GOOD! {accuracy_percent:.1f}% accuracy is solid!\")\n",
    "    print(\"   Your model is performing well!\")\n",
    "elif accuracy_percent >= 80:\n",
    "    print(f\"ğŸ‘ GOOD! {accuracy_percent:.1f}% accuracy is respectable!\")\n",
    "    print(\"   Your model has learned the patterns!\")\n",
    "else:\n",
    "    print(f\"ğŸ“ˆ ROOM FOR IMPROVEMENT: {accuracy_percent:.1f}% accuracy\")\n",
    "    print(\"   Consider: more data, more epochs, or different parameters\")\n",
    "\n",
    "# Compare to baseline\n",
    "print(\"\\nğŸ“Š CONTEXT:\")\n",
    "print(\"  â€¢ Random guessing: 50% accuracy\")\n",
    "print(\"  â€¢ Untrained model: ~50-60% accuracy\")\n",
    "print(f\"  â€¢ Your fine-tuned model: {accuracy_percent:.1f}% accuracy\")\n",
    "print(f\"  â€¢ Improvement: +{accuracy_percent - 50:.1f}% over random!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Confusion Matrix - Where Did We Make Mistakes?\n",
    "\n",
    "The confusion matrix shows:\n",
    "- **True Negatives**: Correctly predicted negative\n",
    "- **True Positives**: Correctly predicted positive\n",
    "- **False Positives**: Wrongly said positive (was negative)\n",
    "- **False Negatives**: Wrongly said negative (was positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š CONFUSION MATRIX CELL - Visualize prediction errors\n",
    "\n",
    "print(\"ğŸ“Š CREATING CONFUSION MATRIX\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get predictions for test set\n",
    "print(\"ğŸ”® Getting model predictions...\")\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'],\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            annot_kws={'size': 14})\n",
    "\n",
    "plt.title('Confusion Matrix - How Well Did We Predict?', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label (Actual)', fontsize=12)\n",
    "plt.xlabel('Predicted Label (Model\\'s Guess)', fontsize=12)\n",
    "\n",
    "# Add text boxes explaining each quadrant\n",
    "plt.text(0.5, -0.15, 'Perfect diagonal = Perfect predictions!', \n",
    "         ha='center', transform=plt.gca().transAxes, fontsize=10, style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display metrics from confusion matrix\n",
    "true_neg, false_pos, false_neg, true_pos = cm.ravel()\n",
    "total = true_neg + false_pos + false_neg + true_pos\n",
    "\n",
    "print(\"\\nğŸ“Š CONFUSION MATRIX BREAKDOWN:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"âœ… True Negatives:  {true_neg:4d} (Correctly predicted negative)\")\n",
    "print(f\"âœ… True Positives:  {true_pos:4d} (Correctly predicted positive)\")\n",
    "print(f\"âŒ False Positives: {false_pos:4d} (Said positive, was negative)\")\n",
    "print(f\"âŒ False Negatives: {false_neg:4d} (Said negative, was positive)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Correct: {true_neg + true_pos}/{total} ({(true_neg + true_pos)/total*100:.1f}%)\")\n",
    "print(f\"Total Wrong:   {false_pos + false_neg}/{total} ({(false_pos + false_neg)/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Detailed Performance Report\n",
    "\n",
    "### Metrics Explained:\n",
    "- **Precision**: When we say positive, how often are we right?\n",
    "- **Recall**: Of all actual positives, how many did we find?\n",
    "- **F1-Score**: Balance between precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‹ CLASSIFICATION REPORT CELL - Detailed metrics\n",
    "\n",
    "print(\"ğŸ“‹ DETAILED CLASSIFICATION REPORT\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, \n",
    "                              target_names=['Negative', 'Positive'],\n",
    "                              digits=3)\n",
    "\n",
    "print(report)\n",
    "\n",
    "print(\"\\nğŸ“– HOW TO READ THIS REPORT:\")\n",
    "print(\"=\"*50)\n",
    "print(\"PRECISION: Of all reviews we labeled as X, what % were correct?\")\n",
    "print(\"  â€¢ High precision = Few false positives\")\n",
    "print(\"  â€¢ Example: 0.90 = 90% of our 'positive' predictions were right\")\n",
    "\n",
    "print(\"\\nRECALL: Of all actual X reviews, what % did we find?\")\n",
    "print(\"  â€¢ High recall = We found most of them\")\n",
    "print(\"  â€¢ Example: 0.85 = We found 85% of all positive reviews\")\n",
    "\n",
    "print(\"\\nF1-SCORE: Harmonic mean of precision and recall\")\n",
    "print(\"  â€¢ Balance between precision and recall\")\n",
    "print(\"  â€¢ Higher is better (max = 1.0)\")\n",
    "\n",
    "print(\"\\nSUPPORT: How many samples in each category\")\n",
    "print(\"  â€¢ Shows data distribution in test set\")\n",
    "\n",
    "print(\"\\nğŸ¯ QUICK ASSESSMENT:\")\n",
    "# Calculate average F1 score\n",
    "report_dict = classification_report(y_true, y_pred, \n",
    "                                   target_names=['Negative', 'Positive'],\n",
    "                                   output_dict=True)\n",
    "avg_f1 = report_dict['macro avg']['f1-score']\n",
    "\n",
    "if avg_f1 > 0.9:\n",
    "    print(f\"  F1-Score of {avg_f1:.3f} = Excellent balanced performance!\")\n",
    "elif avg_f1 > 0.8:\n",
    "    print(f\"  F1-Score of {avg_f1:.3f} = Good balanced performance!\")\n",
    "else:\n",
    "    print(f\"  F1-Score of {avg_f1:.3f} = Room for improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¬ Step 10: Test with Real Movie Reviews!\n",
    "\n",
    "### Let's See Our Model in Action! ğŸ¿\n",
    "\n",
    "Time to test with some real reviews and see how confident our model is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¬ TESTING CELL - Try the model with custom reviews\n",
    "\n",
    "def predict_sentiment(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Predict sentiment for any text.\n",
    "    Returns sentiment, confidence, and probability scores.\n",
    "    \"\"\"\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", \n",
    "                      truncation=True, padding=True, \n",
    "                      max_length=256)\n",
    "    \n",
    "    # Move to correct device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Get prediction (no gradient calculation needed)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    prediction = torch.argmax(probs, dim=-1)\n",
    "    \n",
    "    # Get confidence score\n",
    "    confidence = probs[0][prediction].item()\n",
    "    \n",
    "    # Determine sentiment with emoji\n",
    "    if prediction.item() == 1:\n",
    "        sentiment = \"POSITIVE ğŸ˜Š\"\n",
    "        emoji = \"ğŸ‘\"\n",
    "    else:\n",
    "        sentiment = \"NEGATIVE ğŸ˜\"\n",
    "        emoji = \"ğŸ‘\"\n",
    "    \n",
    "    return sentiment, confidence, probs[0].cpu().numpy(), emoji\n",
    "\n",
    "# Test reviews - mix of easy and challenging\n",
    "test_reviews = [\n",
    "    # Clear positive\n",
    "    \"This movie was absolutely phenomenal! Best film I've seen in years!\",\n",
    "    \n",
    "    # Clear negative\n",
    "    \"Terrible waste of time. I want my money back. Worst movie ever.\",\n",
    "    \n",
    "    # Subtle positive\n",
    "    \"A thoughtful and well-crafted story that stays with you.\",\n",
    "    \n",
    "    # Subtle negative\n",
    "    \"The plot was confusing and the pacing felt off throughout.\",\n",
    "    \n",
    "    # Mixed sentiment (challenging)\n",
    "    \"Great acting but terrible script. Not sure how I feel about it.\",\n",
    "    \n",
    "    # Very short\n",
    "    \"Loved it!\",\n",
    "    \n",
    "    # Sarcastic (challenging)\n",
    "    \"Oh great, another superhero movie. Just what we needed.\",\n",
    "]\n",
    "\n",
    "print(\"ğŸ¬ TESTING WITH CUSTOM MOVIE REVIEWS\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    sentiment, confidence, probs, emoji = predict_sentiment(review, model, tokenizer)\n",
    "    \n",
    "    # Display review\n",
    "    print(f\"Review #{i}:\")\n",
    "    print(f\"ğŸ“ \\\"{review}\\\"\")\n",
    "    print()\n",
    "    \n",
    "    # Display prediction\n",
    "    print(f\"ğŸ¤– Model says: {sentiment} {emoji}\")\n",
    "    print(f\"ğŸ’ª Confidence: {confidence*100:.1f}%\")\n",
    "    \n",
    "    # Visual confidence bar\n",
    "    bar_length = 20\n",
    "    filled = int(bar_length * confidence)\n",
    "    bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)\n",
    "    print(f\"ğŸ“Š [{bar}]\")\n",
    "    \n",
    "    # Detailed scores\n",
    "    print(f\"ğŸ“ˆ Scores: Negative={probs[0]*100:.1f}% | Positive={probs[1]*100:.1f}%\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if confidence > 0.95:\n",
    "        print(\"âœ¨ Very confident prediction!\")\n",
    "    elif confidence > 0.8:\n",
    "        print(\"ğŸ‘ Confident prediction\")\n",
    "    elif confidence > 0.6:\n",
    "        print(\"ğŸ¤” Somewhat uncertain\")\n",
    "    else:\n",
    "        print(\"ğŸ˜• Very uncertain - could go either way\")\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "\n",
    "print(\"\\nğŸ’¡ Note: Lower confidence on mixed/sarcastic reviews is expected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ® Interactive Testing - Try Your Own Reviews!\n",
    "\n",
    "### Your Turn to Test the Model! ğŸ¯\n",
    "\n",
    "Type any movie review and see what the model thinks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ® INTERACTIVE TESTING CELL - User can input their own reviews\n",
    "\n",
    "print(\"ğŸ® INTERACTIVE SENTIMENT ANALYZER\")\n",
    "print(\"=\"*60)\n",
    "print(\"Test the model with your own movie reviews!\")\n",
    "print(\"Type 'quit' to exit\\n\")\n",
    "\n",
    "# Example prompts to inspire users\n",
    "print(\"ğŸ’¡ Try different types of reviews:\")\n",
    "print(\"  â€¢ Clear positive: 'Amazing movie!'\")\n",
    "print(\"  â€¢ Clear negative: 'Boring and slow'\")\n",
    "print(\"  â€¢ Mixed feelings: 'Good acting but weak plot'\")\n",
    "print(\"  â€¢ Your actual opinion about a movie!\\n\")\n",
    "\n",
    "# Interactive loop\n",
    "review_count = 0\n",
    "while review_count < 5:  # Limit to 5 reviews in notebook\n",
    "    user_input = input(f\"\\nğŸ‘¤ Enter review #{review_count + 1} (or 'quit'): \")\n",
    "    \n",
    "    if user_input.lower() == 'quit':\n",
    "        print(\"\\nğŸ‘‹ Thanks for testing the model!\")\n",
    "        break\n",
    "    \n",
    "    if len(user_input.strip()) < 3:\n",
    "        print(\"âš ï¸ Please enter a longer review (at least 3 characters)\")\n",
    "        continue\n",
    "    \n",
    "    # Get prediction\n",
    "    sentiment, confidence, probs, emoji = predict_sentiment(user_input, model, tokenizer)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nğŸ¤– ANALYSIS:\")\n",
    "    print(f\"   Sentiment: {sentiment} {emoji}\")\n",
    "    print(f\"   Confidence: {confidence*100:.1f}%\")\n",
    "    \n",
    "    # Visual confidence meter\n",
    "    bar_length = 30\n",
    "    filled = int(bar_length * confidence)\n",
    "    bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)\n",
    "    print(f\"   Confidence: [{bar}]\")\n",
    "    \n",
    "    # Detailed breakdown\n",
    "    print(f\"\\n   ğŸ“Š Probability Breakdown:\")\n",
    "    print(f\"      Negative: {probs[0]*100:.1f}%\")\n",
    "    print(f\"      Positive: {probs[1]*100:.1f}%\")\n",
    "    \n",
    "    review_count += 1\n",
    "    \n",
    "    if review_count < 5:\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "if review_count == 5:\n",
    "    print(\"\\nğŸ“ Reached 5 reviews limit. Restart cell to test more!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ Great job testing the model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Step 11: Save Your Fine-tuned Model\n",
    "\n",
    "### Time to Save Your Work! ğŸ“¦\n",
    "\n",
    "We'll save:\n",
    "1. The model weights (the learned knowledge)\n",
    "2. The tokenizer (text processor)\n",
    "3. Configuration files\n",
    "\n",
    "This lets you use the model later without retraining!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ SAVE MODEL CELL - Save your fine-tuned model locally\n",
    "\n",
    "print(\"ğŸ’¾ SAVING YOUR FINE-TUNED MODEL\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define save directory\n",
    "save_directory = \"./my_movie_sentiment_model\"\n",
    "\n",
    "print(f\"ğŸ“ Save location: {save_directory}\")\n",
    "print(\"\\nğŸ“¦ Saving components:\")\n",
    "\n",
    "# Save the model\n",
    "print(\"  1. Saving model weights...\")\n",
    "trainer.save_model(save_directory)\n",
    "print(\"     âœ… Model saved!\")\n",
    "\n",
    "# Save the tokenizer\n",
    "print(\"  2. Saving tokenizer...\")\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "print(\"     âœ… Tokenizer saved!\")\n",
    "\n",
    "print(\"\\nâœ… Model successfully saved!\\n\")\n",
    "\n",
    "# Check what was saved\n",
    "import os\n",
    "saved_files = os.listdir(save_directory)\n",
    "\n",
    "print(\"ğŸ“ SAVED FILES:\")\n",
    "print(\"-\" * 40)\n",
    "total_size = 0\n",
    "for file in saved_files:\n",
    "    file_path = os.path.join(save_directory, file)\n",
    "    file_size = os.path.getsize(file_path) / (1024*1024)  # Convert to MB\n",
    "    total_size += file_size\n",
    "    print(f\"  ğŸ“„ {file:30s} ({file_size:6.1f} MB)\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"  ğŸ“Š Total size: {total_size:.1f} MB\")\n",
    "\n",
    "print(\"\\nğŸ“ HOW TO LOAD THIS MODEL LATER:\")\n",
    "print(\"```python\")\n",
    "print(\"from transformers import AutoModelForSequenceClassification, AutoTokenizer\")\n",
    "print(f\"model = AutoModelForSequenceClassification.from_pretrained('{save_directory}')\")\n",
    "print(f\"tokenizer = AutoTokenizer.from_pretrained('{save_directory}')\")\n",
    "print(\"```\")\n",
    "\n",
    "print(\"\\nâœ¨ Your model is saved and ready to use anytime!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 12: Deploy to Hugging Face Hub (Optional)\n",
    "\n",
    "### Share Your Model with the World! ğŸŒ\n",
    "\n",
    "By uploading to Hugging Face:\n",
    "- Anyone can use your model\n",
    "- You get a model card page\n",
    "- Free hosting forever\n",
    "- Version control included\n",
    "\n",
    "### Prerequisites:\n",
    "1. Create account at https://huggingface.co\n",
    "2. Get token from https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ DEPLOYMENT CELL - Upload to Hugging Face Hub\n",
    "\n",
    "print(\"ğŸš€ DEPLOYING TO HUGGING FACE HUB\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"ğŸ“ SETUP INSTRUCTIONS:\")\n",
    "print(\"1. Go to: https://huggingface.co/join (create account)\")\n",
    "print(\"2. Go to: https://huggingface.co/settings/tokens\")\n",
    "print(\"3. Click 'New token'\")\n",
    "print(\"4. Name it, select 'write' permission\")\n",
    "print(\"5. Copy the token\\n\")\n",
    "\n",
    "# Login to Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "print(\"ğŸ” Please login to Hugging Face:\")\n",
    "print(\"(Paste your token in the box below)\\n\")\n",
    "\n",
    "# This creates a login widget\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¤ UPLOAD MODEL CELL - Push to Hugging Face\n",
    "\n",
    "print(\"ğŸ“¤ UPLOADING MODEL TO HUGGING FACE\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Choose a name for your model\n",
    "model_name = \"my-imdb-sentiment-analyzer\"  # Change this to your preference!\n",
    "\n",
    "print(f\"ğŸ“¦ Model name: {model_name}\")\n",
    "print(\"\\nğŸŒ Uploading... (this may take 1-2 minutes)\\n\")\n",
    "\n",
    "try:\n",
    "    # Upload model\n",
    "    print(\"ğŸ“¤ Uploading model...\")\n",
    "    model.push_to_hub(model_name, use_temp_dir=True)\n",
    "    print(\"âœ… Model uploaded!\")\n",
    "    \n",
    "    # Upload tokenizer\n",
    "    print(\"\\nğŸ“¤ Uploading tokenizer...\")\n",
    "    tokenizer.push_to_hub(model_name, use_temp_dir=True)\n",
    "    print(\"âœ… Tokenizer uploaded!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ SUCCESS! Model deployed to Hugging Face Hub!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nğŸŒ Your model page: https://huggingface.co/YOUR_USERNAME/{model_name}\")\n",
    "    print(\"   (Replace YOUR_USERNAME with your Hugging Face username)\")\n",
    "    \n",
    "    print(\"\\nğŸ“ HOW OTHERS CAN USE YOUR MODEL:\")\n",
    "    print(\"```python\")\n",
    "    print(\"from transformers import pipeline\")\n",
    "    print(f\"classifier = pipeline('sentiment-analysis', model='YOUR_USERNAME/{model_name}')\")\n",
    "    print(\"result = classifier('This movie is amazing!')\")\n",
    "    print(\"print(result)\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\nğŸŠ Congratulations! You've deployed an AI model!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ Upload failed: {str(e)}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Make sure you're logged in with a valid token\")\n",
    "    print(\"2. Check your internet connection\")\n",
    "    print(\"3. Verify your token has 'write' permissions\")\n",
    "    print(\"\\nğŸ’¡ Your model is still saved locally and works fine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Final Summary - What You've Accomplished!\n",
    "\n",
    "### ğŸ† Congratulations! You've Successfully:\n",
    "\n",
    "âœ… **Loaded** a pre-trained DistilBERT model  \n",
    "âœ… **Prepared** movie review data for training  \n",
    "âœ… **Fine-tuned** the model on sentiment analysis  \n",
    "âœ… **Achieved** ~{accuracy}% accuracy!  \n",
    "âœ… **Tested** with custom reviews  \n",
    "âœ… **Saved** your model locally  \n",
    "âœ… **Deployed** to Hugging Face (optional)  \n",
    "\n",
    "### ğŸ“Š Your Model's Journey:\n",
    "\n",
    "```\n",
    "Start: Generic language model (50% accuracy on sentiment)\n",
    "                    â†“\n",
    "         Fine-tuning with YOUR data\n",
    "                    â†“\n",
    "End: Specialized sentiment expert (~90%+ accuracy!)\n",
    "```\n",
    "\n",
    "### ğŸ”‘ Key Skills You've Learned:\n",
    "\n",
    "1. **Transfer Learning** - Using pre-trained models\n",
    "2. **Data Preparation** - Converting text to model format\n",
    "3. **Fine-tuning** - Specializing models for your task\n",
    "4. **Evaluation** - Measuring model performance\n",
    "5. **Deployment** - Sharing models with others\n",
    "\n",
    "### ğŸš€ What Can You Do Next?\n",
    "\n",
    "#### With Your Current Model:\n",
    "- Build a web app for movie review analysis\n",
    "- Create an API endpoint\n",
    "- Analyze movie review datasets\n",
    "- Add to your portfolio!\n",
    "\n",
    "#### Apply to Your Field (Electrical Engineering):\n",
    "- **Equipment logs**: Classify failure types\n",
    "- **Maintenance reports**: Predict urgency levels\n",
    "- **Customer feedback**: Analyze satisfaction\n",
    "- **Technical docs**: Categorize by topic\n",
    "\n",
    "### ğŸ“š Resources for Continued Learning:\n",
    "\n",
    "1. **Hugging Face Course** (Free!): https://huggingface.co/course\n",
    "2. **Model Hub**: https://huggingface.co/models\n",
    "3. **Documentation**: https://huggingface.co/docs\n",
    "4. **Community**: https://discuss.huggingface.co\n",
    "\n",
    "### ğŸ’¡ Final Thoughts:\n",
    "\n",
    "> \"You've just trained an AI model that understands human sentiment!\n",
    "> This same technique powers ChatGPT, Google Search, and countless\n",
    "> AI applications. You're now part of the AI revolution!\"\n",
    "\n",
    "### ğŸ‰ Amazing Work! You're Now an AI Practitioner!\n",
    "\n",
    "---\n",
    "\n",
    "## Questions? Let's Discuss! ğŸ™‹â€â™‚ï¸ğŸ™‹â€â™€ï¸\n",
    "\n",
    "Feel free to ask about:\n",
    "- How to improve accuracy\n",
    "- Different model architectures\n",
    "- Applying to your specific use case\n",
    "- Troubleshooting issues\n",
    "- Next steps in your AI journey\n",
    "\n",
    "**Thank you for joining this session!** ğŸ™"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}